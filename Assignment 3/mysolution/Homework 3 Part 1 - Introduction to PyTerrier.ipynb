{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Homework 3 Part 1 - Introduction to PyTerrier.ipynb","provenance":[{"file_id":"1kWCNf3QlQ4bX5YCM9OJBaaLikoTFCd5A","timestamp":1615914442515},{"file_id":"17Pihqt_C8DFzqlomTUks-5stNzNFjrAn","timestamp":1611078807322},{"file_id":"121AtOADdFd2VVAX5hcJX0WNBNt2_QHDu","timestamp":1609952873856},{"file_id":"1o4RTKOutf_FlMyPdEPkRyutnbY26JXMf","timestamp":1571324862553}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6UxEkLc6yz6J"},"source":["# SI 650 / EECS 549: Homework 3 Part 1\n","## Introduction to PyTerrier \n","\n","This homework is intended to expose you to other types of information retrieval and demonstrates the use of another state of the art IR library, [PyTerrier](https://github.com/terrier-org/pyterrier). \n","\n","The overall learning goals of the assignment across all three parts are\n","  - Learn how to use PyTerrier\n","  - Understand how to train and use a Learning to Rank model\n","  - Understand how to train and use a dense vector retrieval (using deep learning)\n","  - Understand how to use document augmentation\n","  - Gain additional programming and debugging skills when working with modern IR libraries\n","  - Learn how to use the [Great Lakes cluster](https://arc.umich.edu/greatlakes/)\n","  \n","  \n","The Great Lakes cluster is a collection of high performance computers at the University of Michigan. The big advantage for this course is the ability to use its GPUs for doing deep learning. You will have access to this cluster for Homework 3 _and_ for your course project, which can expand the type of methods you can try. When launching jobs for this course, be sure to have your job use the `si650f21_class` account.\n","\n","For this assignment, we'll be using the [CORD19 test collection](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge), which is a collection of documents about Covid-19 produced by AI2. In places, we've pretrained models and precomputed indices for you (which can take large amounts of time), but we'll ask you to try out the commands on a small scale so you'll know how to run them.\n","\n","Homework 3 Part 1 will have you working on the following tasks to get you started:\n","  - PyTerrier installation & configuration\n","  - indexing a collection\n","  - accessing an index\n","  - using the `BatchRetrieve` transformer for searching an index\n","  - conducting an `Experiment` \n","\n","For all parts of the homework, you can run them on your local computer with enough time. However, for Part 3, you will see *significant* speed up running these as notebooks on Great Lakes with a GPU. The three parts are designed to be completed in order, as they build on each other conceptually.\n","\n","For each notebook, all the tasks that you will need to complete are marked with **Task** in a cell title comment.\n","\n","Note that just like Pyserini, PyTerrier also uses a Java-based  library underneath, [Terrier information retrieval toolkit](http://terrier.org), so you will need to set `JAVA_HOME` accordingly. underlying for many indexing and retrieval operations. PyTerrier is relatively new in 2020, but Terrier has a long history dating back to 2001 and  makes it easy to perform IR experiments in Python, which could come in handy for you when doing your course project.\n","\n","See the [PyTerrier documentation](https://pyterrier.readthedocs.io/en/latest/) for many more details."]},{"cell_type":"markdown","metadata":{"id":"7u2hD-zBzfpR"},"source":["PyTerrier is a Python framework, but uses the underlying [Terrier information retrieval toolkit](http://terrier.org) for many indexing and retrieval operations. While PyTerrier was new in 2020, Terrier is written in Java and has a long history dating back to 2001. PyTerrier makes it easy to perform IR experiments in Python, but using the mature Terrier platform for the expensive indexing and retrieval operations. \n","\n","In the following, we introduce everything you need to know about PyTerrier, and also provide appropriate links to relevant parts of the [PyTerrier documentation](https://pyterrier.readthedocs.io/en/latest/).\n"]},{"cell_type":"code","metadata":{"id":"YpOmOyEN0wDR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637338525166,"user_tz":300,"elapsed":3370,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"780e2a12-8d15-4bd5-f125-805e2917bb52"},"source":["! pip install python-terrier"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: python-terrier in /usr/local/lib/python3.7/dist-packages (0.7.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.23.0)\n","Requirement already satisfied: deprecation in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.1.0)\n","Requirement already satisfied: ir-datasets>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.4.3)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.10.2)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.3.4)\n","Requirement already satisfied: chest in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.2.3)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from python-terrier) (8.11.0)\n","Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (from python-terrier) (3.2)\n","Requirement already satisfied: pyjnius~=1.3.0 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.3.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from python-terrier) (4.62.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.11.3)\n","Requirement already satisfied: nptyping in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.4.4)\n","Requirement already satisfied: matchpy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.5.5)\n","Requirement already satisfied: ir-measures>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.2.1)\n","Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (3.1.4)\n","Requirement already satisfied: pyautocorpus>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.6)\n","Requirement already satisfied: lz4>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (3.1.3)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (6.0)\n","Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.6.3)\n","Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.3)\n","Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (2.5.4)\n","Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.6.4)\n","Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\n","Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\n","Requirement already satisfied: pytrec-eval-terrier==0.5.1 in /usr/local/lib/python3.7/dist-packages (from ir-measures>=0.2.0->python-terrier) (0.5.1)\n","Requirement already satisfied: cwl-eval>=1.0.10 in /usr/local/lib/python3.7/dist-packages (from ir-measures>=0.2.0->python-terrier) (1.0.10)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from pyjnius~=1.3.0->python-terrier) (0.29.24)\n","Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius~=1.3.0->python-terrier) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (2021.10.8)\n","Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\n","Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from chest->python-terrier) (1.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation->python-terrier) (21.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->python-terrier) (2.0.1)\n","Requirement already satisfied: multiset<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from matchpy->python-terrier) (2.1.1)\n","Requirement already satisfied: typish>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from nptyping->python-terrier) (1.9.3)\n","Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation->python-terrier) (2.4.7)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->python-terrier) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->python-terrier) (2.8.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->python-terrier) (1.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->python-terrier) (3.0.0)\n","Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->python-terrier) (0.5.2)\n"]}]},{"cell_type":"markdown","metadata":{"id":"WGrkN2v50wDU"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"E60dKh7m0wDV"},"source":["import pandas as pd\n","# Helpful for showing indexing information\n","pd.set_option('display.max_colwidth', 150)\n","\n","import pyterrier as pt\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iH0Ds2370V0G"},"source":["### Starting PyTerrier\n","\n","The first step is to initialize PyTerrier using PyTerrier's `init()` method. The `init()` method will download Terrier's jar file (if it's not already) and then start the Java Virtual Machine. To avoid downstream complications, we check `started()` prior to calling `init()` to prevent multiple Terrier instances from running concurrently."]},{"cell_type":"code","metadata":{"id":"Z4qALBa90-7g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637338530286,"user_tz":300,"elapsed":2649,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"42d7fb48-32b1-46fc-8a72-9fdda7835580"},"source":["if not pt.started():\n","    pt.init()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["terrier-assemblies 5.6 jar-with-dependencies not found, downloading to /root/.pyterrier...\n","Done\n","terrier-python-helper 0.0.6 jar not found, downloading to /root/.pyterrier...\n","Done\n","PyTerrier 0.7.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n"]}]},{"cell_type":"markdown","metadata":{"id":"-qqjVSu-5_FX"},"source":["### Documents, Indexing and Indexes"]},{"cell_type":"markdown","metadata":{"id":"3soS1IIy5B83"},"source":["PyTerrier typically works with Pandas dataframes for inputs. Let's create a toy set of documents in a dataframe to test. Note that the column name of `docno` is a special PyTerrier name that is the unique identifier for each document."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"gSEiEuTE5uyL","executionInfo":{"status":"ok","timestamp":1637296974000,"user_tz":300,"elapsed":12,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"80292857-1315-4538-fe70-3c3a1eea5814"},"source":["docs_df = pd.DataFrame([\n","        [\"d1\", \"this is the first document of many documents\"],\n","        [\"d2\", \"this is another document\"],\n","        [\"d3\", \"the topic of this document is unknown\"]\n","    ], columns=[\"docno\", \"text\"])\n","\n","docs_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>docno</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>d1</td>\n","      <td>this is the first document of many documents</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>d2</td>\n","      <td>this is another document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>d3</td>\n","      <td>the topic of this document is unknown</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  docno                                          text\n","0    d1  this is the first document of many documents\n","1    d2                      this is another document\n","2    d3         the topic of this document is unknown"]},"metadata":{},"execution_count":84}]},{"cell_type":"markdown","metadata":{"id":"2RCtCCTU6GAj"},"source":["Before any search engine can estimate which documents are most likely to be relevant for a given query, it must index the documents. \n","\n","In the following cell, we index the dataframe's documents. The index, with all its data structures, is written into a directory called `toydocs_index`. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"1YvLhEOS6V8w","executionInfo":{"status":"ok","timestamp":1637296976114,"user_tz":300,"elapsed":775,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"d17ddb63-31a0-41e1-f329-93651eb78ece"},"source":["index_dir = './toydocs_index'\n","indexer = pt.DFIndexer(index_dir, overwrite=True)\n","index_ref = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])\n","index_ref.toString()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./toydocs_index/data.properties'"]},"metadata":{},"execution_count":85}]},{"cell_type":"markdown","metadata":{"id":"TUm6r6_625gW"},"source":["PyTerrier will generate a index in the `toydocs_index` directory and and we can list the files to see what kind of internal structure and files it made"]},{"cell_type":"code","metadata":{"id":"TF45pl5O8p7R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637296977498,"user_tz":300,"elapsed":203,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"ca329ba6-accc-4c6d-b739-84035f78a5eb"},"source":["os.listdir(index_dir)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['data.lexicon.fsomaphash',\n"," 'data.inverted.bf',\n"," 'data.meta.zdata',\n"," 'data.meta-0.fsomapfile',\n"," 'data.direct.bf',\n"," 'data.document.fsarrayfile',\n"," 'data.lexicon.fsomapfile',\n"," 'data.properties',\n"," 'data.meta.idx']"]},"metadata":{},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"B2b8isFP3Kv6"},"source":["Once we've generated the files associated with `index_ref`, we can load the information into an actual PyTerrier index using the method `pt.IndexFactory.of()`. "]},{"cell_type":"code","metadata":{"id":"TTM17szD6pNy"},"source":["index = pt.IndexFactory.of(index_ref)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mZe3HD5i7G3v"},"source":["See Terrier's [`Index`](http://terrier.org/docs/current/javadoc/org/terrier/structures/Index.html) object for documentation, which is written in Java's Javadoc format. We can call these methods on our index object as well. Important methods to note are:\n"," - `getCollectionStatistics()`\n"," - `getInvertedIndex()`\n"," - `getLexicon()`\n","\n","Let's see what is returned by the `CollectionStatistics()` method:"]},{"cell_type":"code","metadata":{"id":"6-gXEDSX65bx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637296980521,"user_tz":300,"elapsed":152,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"40b503d1-d057-45fa-8055-f890e4c44349"},"source":["print(index.getCollectionStatistics().toString())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of documents: 3\n","Number of terms: 4\n","Number of postings: 6\n","Number of fields: 1\n","Number of tokens: 7\n","Field names: [abstract]\n","Positions:   false\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"i6HrR4lc7i10"},"source":["Let's unpack the statistics a bit more. We have 3 documents but why do we have only 4 unique terms? We can look at which terms we have by getting the [`Lexicon`](http://terrier.org/docs/current/javadoc/org/terrier/structures/Lexicon.html) object, which contains our vocabulary. We can iterate over the `Lexicon` from Python like a dictionary to see which terms are present and what information there is about each term after indexing."]},{"cell_type":"code","metadata":{"id":"us2mAzTW7Bny","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637297035834,"user_tz":300,"elapsed":144,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"959e872c-f259-4a23-a5ef-92214cd827c6"},"source":["for kv in index.getLexicon():\n","    # Let's all print the type information of each to get a sense of what we're working with\n","    print(\"%s (%s) -> %s (%s)\" % (kv.getKey(), type(kv.getKey()), kv.getValue().toString(), type(kv.getValue()) ) )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["document (<class 'str'>) -> term0 Nt=3 TF=4 maxTF=2 @{0 0 0} TFf=0 (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n","first (<class 'str'>) -> term1 Nt=1 TF=1 maxTF=1 @{0 1 2} TFf=0 (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n","topic (<class 'str'>) -> term2 Nt=1 TF=1 maxTF=1 @{0 1 5} TFf=0 (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n","unknown (<class 'str'>) -> term3 Nt=1 TF=1 maxTF=1 @{0 2 2} TFf=0 (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"fwbp94gh86pw"},"source":["Iterating over the `Lexicon` shows that we're mapping a `String ` term to a [`LexiconEntry`](http://terrier.org/docs/current/javadoc/org/terrier/structures/LexiconEntry.html) object, which itself is an [`EntryStatistics`](http://terrier.org/docs/current/javadoc/org/terrier/structures/EntryStatistics.html). The `LexiconEntry` contains information including the statistics of that term.\n","\n","Looking at what we indexed reveals that PyTerrier is removing stopwords for us, much like Pyserini did. PyTerrier is also doing some token normalization as well so that we only have \"document\" in our index, even though document `d1` has the token \"documents\"! By default, Terrier removes standard stopwords and applies Porter's stemmer (which we talked about in class), though these behaviors can be configured.\n","\n","The `EntryStatistics` also provides a few other fields that offer insights:\n"," - `Nt` is the number of unique documents that each term occurs in – this is useful for calculating IDF.\n"," - `TF` is the total number of occurrences – some weighting models use this instead of Nt.\n"," - The numbers in the `@{}` are a pointer – they tell Terrier where the postings are for that term in the inverted index data structure."]},{"cell_type":"markdown","metadata":{"id":"GwZimzMD0wDe"},"source":["PyTerrier also supports directly looking up a word using the `[]` operator, much like we would if we were looking up a key's value in a dictionary. Let's look up the value for the word \"document\":"]},{"cell_type":"code","metadata":{"id":"SZmi9498-Ijw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637297470258,"user_tz":300,"elapsed":212,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"c75e0bee-d383-4e23-ed73-626f778b8f96"},"source":["print(index.getLexicon()[\"document\"])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["term0 Nt=3 TF=4 maxTF=2 @{0 0 0} TFf=0\n"]}]},{"cell_type":"markdown","metadata":{"id":"vaKaU59l-kzg"},"source":["We can use the information in the `Lexicon` to also look up documents as well. Remember from class that an inverted index is a mapping from a term to which *documents* each term occurs in. The `LexiconEntry` for a word contains the pointer to where to find the documents for that word in the inverted index. \n","\n","The object retrieved from using the `[]` operator with a `Lexicon` is a pointer that we can use with the inverted index."]},{"cell_type":"code","metadata":{"id":"XQki_Pds8ut2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637297799332,"user_tz":300,"elapsed":136,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"b403f65d-de64-486a-b9a8-6401cfb8d605"},"source":["pointer = index.getLexicon()[\"document\"]\n","for posting in index.getInvertedIndex().getPostings(pointer):\n","    print(str(posting) + \" doclen=%d\" % posting.getDocumentLength())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(0,2,F[0]) doclen=3\n","(1,1,F[0]) doclen=1\n","(2,1,F[0]) doclen=3\n"]}]},{"cell_type":"markdown","metadata":{"id":"l7EaoIIO_DPx"},"source":["From this output, we can see that the term \"document\" occurs in all three documents, as well as how long those documents are. Note that PyTerrier starts counting indexed documents with `int` values starting from 0 (called *docids*). These *docids* are then mapped back to *docnos*, which are the unique string identifiers for a document, e.g., the \"`d1`\", \"`d2`\" we used. This mapping is stored in a separate data structure called the *metaindex*, though you likely won't need to use that."]},{"cell_type":"markdown","metadata":{"id":"zOSdVAr-CGRf"},"source":["## Searching an Index\n","\n","Our way into search in PyTerrier is called `BatchRetrieve`. BatchRetrieve is configured by specifying an index and a weighting model. Here', we'll use the `Tf` weighting, which is just term frequency; there are multiple possible weighting schemes, as we'll see later. Using a `BatchRetrieve` object, we will search for a single-word query, `\"document\"`."]},{"cell_type":"code","metadata":{"id":"XtK93nwXCF5C","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1637297861653,"user_tz":300,"elapsed":201,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"d99257cc-43ed-42c5-fdb5-dbf949007018"},"source":["br = pt.BatchRetrieve(index, wmodel=\"Tf\")\n","br.search(\"document\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>2.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid  docid docno  rank  score     query\n","0   1      0    d1     0    2.0  document\n","1   1      1    d2     1    1.0  document\n","2   1      2    d3     2    1.0  document"]},"metadata":{},"execution_count":102}]},{"cell_type":"markdown","metadata":{"id":"BHqSfTCtDM2T"},"source":["The `search()` method returns a Pandas dataframe with columns:\n"," - `qid`: this is the query id, which is by default \"1\", since we issued only one query\n"," - `docid`: Terrier' internal integer for each document\n"," - `docno`: the external (string) unique identifier for each document\n"," - `score`: since we use the `Tf` weighting model, this score corresponds to the total frequency of the query (terms) in each document\n"," - `rank`: A handy attribute showing the descending order by score\n"," - `query`: the input query\n","\n","As expected, the `Tf` weighting model used here only counts the frequencies of the query terms in each document, i.e.:\n","$$\n","score(d,q) = \\sum_{t \\in q} tf_{t,d}\n","$$\n","\n","Hence, it's clear that document `d1` should be the highest scored document with two occurrences (c.f. `'document'` and `'documents'`).  "]},{"cell_type":"markdown","metadata":{"id":"BJBXquPOD6q7"},"source":["### Searching with multiple queries\n","\n","We can search for more than one query at a time using the  `transform()` method rather than the `search()` method. PyTerrier uses the notion of transformers, which we'll describe much more in Part 2, but for now, you can think of this function as transforming some input to some output. In our case, we'll create a Pandas DataFrame with our queries, which we'll provide as input to the `BatchRetrieve` object, to \"transform\" into results.\n","\n","Note that we not only need to provide queries, but also query identifiers in the `qid` column. These `qid` values will let us distinguish which results go to which query."]},{"cell_type":"code","metadata":{"id":"Yd8BL3MG0wDg","colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"status":"ok","timestamp":1637294342487,"user_tz":300,"elapsed":124,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"2a0e5df1-bb2f-4ddd-ad51-8efd621682c3"},"source":["queries = pd.DataFrame([[\"q1\", \"document\"], [\"q2\", \"first document\"]], columns=[\"qid\", \"query\"])\n","queries"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>q1</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>q2</td>\n","      <td>first document</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid           query\n","0  q1        document\n","1  q2  first document"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","metadata":{"id":"TuOUm0Zq0wDg"},"source":["Now we can pass this queries data frame into `transform()` to get the results"]},{"cell_type":"code","metadata":{"id":"TPBmPOETBKWk","colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"status":"ok","timestamp":1637294348158,"user_tz":300,"elapsed":127,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"0a4f3cc1-30b6-4bec-f6ff-91941296a1da"},"source":["br.transform(queries)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>q1</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>2.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>q1</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>q1</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>q2</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>q2</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>q2</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid  docid docno  rank  score           query\n","0  q1      0    d1     0    2.0        document\n","1  q1      1    d2     1    1.0        document\n","2  q1      2    d3     2    1.0        document\n","3  q2      0    d1     0    3.0  first document\n","4  q2      1    d2     1    1.0  first document\n","5  q2      2    d3     2    1.0  first document"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","metadata":{"id":"tcgDzFLBEWAI"},"source":["Most common operations in PyTerrier have to be overloaded so that you can call them using python syntax (called _operator overloading_). We'll discuss this more in Part 2, but for now, know that you can call `br.transform(queries)` using just `br(queries)`. Here. the `()` operator has been overloaded so that it calls `transform()` for us! You will see this usage very frequently in examples and documentation so it's worth noting and remembering the two are equivalent. As an example:"]},{"cell_type":"code","metadata":{"id":"YCwxb3HhEOp_","colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"status":"ok","timestamp":1637294350975,"user_tz":300,"elapsed":165,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"15e0a0a4-c375-4e95-f673-c841558b4c78"},"source":["br(queries)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>q1</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>2.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>q1</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>q1</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>q2</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>q2</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>q2</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid  docid docno  rank  score           query\n","0  q1      0    d1     0    2.0        document\n","1  q1      1    d2     1    1.0        document\n","2  q1      2    d3     2    1.0        document\n","3  q2      0    d1     0    3.0  first document\n","4  q2      1    d2     1    1.0  first document\n","5  q2      2    d3     2    1.0  first document"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","metadata":{"id":"ldY8VV8wQ60Z"},"source":["## Scaling up to Covid-19 Data\n","\n","Let's move on to our full dataset, CORD19, which is easily accessible online. We'll use PyTerrier's `get_dataset()` function to download this corpus automatically and then to index it.\n","\n","### Task 1: Indexing data (5 points)\n","\n","You first task will be to write three lines of code that create the index using an indexer or, if the index was already created, loads the created index from file. "]},{"cell_type":"code","metadata":{"id":"L2lJsK-vEcQx"},"source":["cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n","pt_index_path = './terrier_trec_covid'\n","\n","if not os.path.exists(pt_index_path + \"/data.properties\"):\n","\n","    # create the index, using the IterDictIndexer indexer \n","\n","    # TODO\n","    indexer = pt.index.IterDictIndexer(pt_index_path)\n","\n","    # we give the dataset get_corpus_iter() directly to the indexer\n","    # while specifying the fields to index and the metadata to record\n","    \n","    # TODO\n","    index_ref = indexer.index(cord19.get_corpus_iter(), \n","                              fields=('abstract', ), \n","                              meta=('docno', ))\n","else:\n","    # if you already have the index, create an IndexRef from the data in pt_index_path\n","    # that we can use to load using the IndexFactory\n","    \n","    # TODO\n","    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n","    \n","index = pt.IndexFactory.of(index_ref)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y7GK9uANRt8w"},"source":["### Task 2: 3 points\n","- Print out the statistics of the index"]},{"cell_type":"code","metadata":{"id":"bNAVqf9uRr2p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637298004432,"user_tz":300,"elapsed":133,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"8d91ee7f-651b-4f54-899f-e86932252be1"},"source":["# TODO\n","print(index.getCollectionStatistics().toString())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of documents: 192509\n","Number of terms: 151235\n","Number of postings: 11554033\n","Number of fields: 1\n","Number of tokens: 17728468\n","Field names: [abstract]\n","Positions:   false\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"tQD9Q8CqSirN"},"source":["As a curated collection, CORD19 has a corresponding set of queries, referred to as _topics_, and the relevance assessments for each query (i.e., topic), referred to as _qrels_. We use these to evaluate as a *test collection*. PyTerrier allows us to easily access the topics (queries) and qrels from the dataset. Like much of the inputs and outputs, these are expressed as dataframes as well:"]},{"cell_type":"code","metadata":{"id":"8n7oY-YYS_-A","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1637298224913,"user_tz":300,"elapsed":136,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"6873ecad-b959-4d19-fe22-a640f7e45fe6"},"source":["cord19.get_topics(variant='title').head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>coronavirus origin</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>coronavirus response to weather changes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>coronavirus immunity</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>how do people die from the coronavirus</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>animal models of covid 19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid                                    query\n","0   1                       coronavirus origin\n","1   2  coronavirus response to weather changes\n","2   3                     coronavirus immunity\n","3   4   how do people die from the coronavirus\n","4   5                animal models of covid 19"]},"metadata":{},"execution_count":114}]},{"cell_type":"code","metadata":{"id":"-rYxqvhJTGNX","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1637298219870,"user_tz":300,"elapsed":530,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"7445306c-83bd-4947-8d87-43891b8f81d9"},"source":["cord19.get_qrels().head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docno</th>\n","      <th>label</th>\n","      <th>iteration</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>005b2j4b</td>\n","      <td>2</td>\n","      <td>4.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>00fmeepz</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>010vptx3</td>\n","      <td>2</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0194oljo</td>\n","      <td>1</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>021q9884</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid     docno  label iteration\n","0   1  005b2j4b      2       4.5\n","1   1  00fmeepz      1         4\n","2   1  010vptx3      2       0.5\n","3   1  0194oljo      1       2.5\n","4   1  021q9884      1         4"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","metadata":{"id":"2Gop4-jVbIIu"},"source":["### Weighting Models\n","\n","In the earlier example, we used the simple \"`Tf`\" as our ranking function for document retrieval in BatchRetrieve. However, we can use other models such as `\"TF_IDF\"` by simply changing the `wmodel=\"Tf\"` keyword argument in the constructor of `BatchRetrieve`:"]},{"cell_type":"code","metadata":{"id":"Cg8AGzCibdPG","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1637298248426,"user_tz":300,"elapsed":522,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"afe6e924-af58-4bc9-d0f4-acb26a66075f"},"source":["tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n","tfidf.search(\"chemical reactions\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>18717</td>\n","      <td>iavwkdpr</td>\n","      <td>0</td>\n","      <td>11.035982</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>171636</td>\n","      <td>v3blnh02</td>\n","      <td>1</td>\n","      <td>10.329726</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>147193</td>\n","      <td>ei4rb8fr</td>\n","      <td>2</td>\n","      <td>10.317138</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>121217</td>\n","      <td>msdycum2</td>\n","      <td>3</td>\n","      <td>9.653734</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>170863</td>\n","      <td>sj8i9ss2</td>\n","      <td>4</td>\n","      <td>9.500211</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>1</td>\n","      <td>2428</td>\n","      <td>38aabxh1</td>\n","      <td>995</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>1</td>\n","      <td>14752</td>\n","      <td>u709r8ss</td>\n","      <td>996</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>1</td>\n","      <td>20074</td>\n","      <td>wxi1xsbo</td>\n","      <td>997</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>1</td>\n","      <td>117156</td>\n","      <td>ts3obwts</td>\n","      <td>998</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>1</td>\n","      <td>149517</td>\n","      <td>6i3x49p8</td>\n","      <td>999</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 6 columns</p>\n","</div>"],"text/plain":["    qid   docid     docno  rank      score               query\n","0     1   18717  iavwkdpr     0  11.035982  chemical reactions\n","1     1  171636  v3blnh02     1  10.329726  chemical reactions\n","2     1  147193  ei4rb8fr     2  10.317138  chemical reactions\n","3     1  121217  msdycum2     3   9.653734  chemical reactions\n","4     1  170863  sj8i9ss2     4   9.500211  chemical reactions\n","..   ..     ...       ...   ...        ...                 ...\n","995   1    2428  38aabxh1   995   3.790183  chemical reactions\n","996   1   14752  u709r8ss   996   3.790183  chemical reactions\n","997   1   20074  wxi1xsbo   997   3.790183  chemical reactions\n","998   1  117156  ts3obwts   998   3.790183  chemical reactions\n","999   1  149517  6i3x49p8   999   3.790183  chemical reactions\n","\n","[1000 rows x 6 columns]"]},"metadata":{},"execution_count":115}]},{"cell_type":"markdown","metadata":{"id":"m6aZGX9sbdmc"},"source":["Note that, as expected, because we switched the ranking, the scores of documents ranked by `TF_IDF` are no longer integers. You can see the exact TF-IDF formula used by Terrier from [the Github repo](https://github.com/terrier-org/terrier-core/blob/5.x/modules/core/src/main/java/org/terrier/matching/models/TF_IDF.java#L79)--sometimes helpful to know since there are multiple ways of defining TF-IDF! Terrier supports many weighting models and the documentation contains [a list of supported models](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html)."]},{"cell_type":"markdown","metadata":{"id":"YQ0j9lFfx-gO"},"source":["## Evaluating and Comparing IR Models\n","\n","How do we know which of the models we've made so far are good IR models? PyTerrier provides a robust and extensive framework to help us automate the evaluation of IR models once we've defined them.\n","\n","As a first pass, let's take a look at the relevance scores in the dataset. To do this, we'll merge (`join`) the `qrels` with the results of our ranker to produce a dataframe that has both the ranking model's predictions (`\"score\"`) and the actual relevance score (`\"label\"`). "]},{"cell_type":"code","metadata":{"id":"iyShZYpwwNSx","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1637298888986,"user_tz":300,"elapsed":739,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"89ffe104-8903-44ea-f848-f8852b27bc25"},"source":["qrels = cord19.get_qrels()\n","\n","def get_res_with_labels(ranker, df):\n","    # get the results for the query or queries\n","    results = ranker( df )\n","    # left outer join with the qrels\n","    with_labels = results.merge(qrels, on=[\"qid\", \"docno\"], how=\"left\").fillna(0)\n","    return with_labels\n","\n","# lets get the Tf results for the first query\n","get_res_with_labels(tfidf, cord19.get_topics(variant='title').head(1))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","      <th>label</th>\n","      <th>iteration</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>175892</td>\n","      <td>zy8qjaai</td>\n","      <td>0</td>\n","      <td>7.080599</td>\n","      <td>coronavirus origin</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>82224</td>\n","      <td>8ccl9aui</td>\n","      <td>1</td>\n","      <td>6.775667</td>\n","      <td>coronavirus origin</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>135326</td>\n","      <td>ne5r4d4b</td>\n","      <td>2</td>\n","      <td>6.683114</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>1.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>122804</td>\n","      <td>75773gwg</td>\n","      <td>3</td>\n","      <td>6.590340</td>\n","      <td>coronavirus origin</td>\n","      <td>2.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>122805</td>\n","      <td>kn2z7lho</td>\n","      <td>4</td>\n","      <td>6.590340</td>\n","      <td>coronavirus origin</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>1</td>\n","      <td>180809</td>\n","      <td>0y0hau9l</td>\n","      <td>995</td>\n","      <td>4.214228</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>1</td>\n","      <td>148967</td>\n","      <td>f8vbflx6</td>\n","      <td>996</td>\n","      <td>4.212887</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>1</td>\n","      <td>183189</td>\n","      <td>uadfehr6</td>\n","      <td>997</td>\n","      <td>4.210201</td>\n","      <td>coronavirus origin</td>\n","      <td>2.0</td>\n","      <td>1.5</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>1</td>\n","      <td>67321</td>\n","      <td>n5hnx2c3</td>\n","      <td>998</td>\n","      <td>4.202319</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>1</td>\n","      <td>98706</td>\n","      <td>ad6ztoba</td>\n","      <td>999</td>\n","      <td>4.202319</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 8 columns</p>\n","</div>"],"text/plain":["    qid   docid     docno  rank     score               query  label iteration\n","0     1  175892  zy8qjaai     0  7.080599  coronavirus origin    1.0         1\n","1     1   82224  8ccl9aui     1  6.775667  coronavirus origin    2.0         1\n","2     1  135326  ne5r4d4b     2  6.683114  coronavirus origin    0.0       1.5\n","3     1  122804  75773gwg     3  6.590340  coronavirus origin    2.0         5\n","4     1  122805  kn2z7lho     4  6.590340  coronavirus origin    2.0         3\n","..   ..     ...       ...   ...       ...                 ...    ...       ...\n","995   1  180809  0y0hau9l   995  4.214228  coronavirus origin    0.0         0\n","996   1  148967  f8vbflx6   996  4.212887  coronavirus origin    0.0         0\n","997   1  183189  uadfehr6   997  4.210201  coronavirus origin    2.0       1.5\n","998   1   67321  n5hnx2c3   998  4.202319  coronavirus origin    0.0         0\n","999   1   98706  ad6ztoba   999  4.202319  coronavirus origin    0.0         0\n","\n","[1000 rows x 8 columns]"]},"metadata":{},"execution_count":116}]},{"cell_type":"markdown","metadata":{"id":"fz8mJz5A0wDj"},"source":["### Running an Experiment\n","\n","We don't actually need to produce that dataframe to do our evaluation though! PyTerrier lets us run different results with an [Experiment](https://pyterrier.readthedocs.io/en/latest/experiments.html) object, which will compare models according to the evaluation metrics we specify. Here, let's run an experiment to evaluate our `tfidf` model that we created earlier:"]},{"cell_type":"code","metadata":{"id":"OFUmiFSobUDg","colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"status":"ok","timestamp":1637298999873,"user_tz":300,"elapsed":4173,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"64857555-3dab-4cd9-c360-64542b56ff93"},"source":["pt.Experiment(\n","    [tfidf],\n","    cord19.get_topics(variant='title'),\n","    cord19.get_qrels(),\n","    eval_metrics=[\"map\", \"ndcg\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>map</th>\n","      <th>ndcg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BR(TF_IDF)</td>\n","      <td>0.180002</td>\n","      <td>0.370767</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         name       map      ndcg\n","0  BR(TF_IDF)  0.180002  0.370767"]},"metadata":{},"execution_count":117}]},{"cell_type":"markdown","metadata":{"id":"Mt0iPhRw2J-S"},"source":["## Task 3: Define new models and evaluate them in an Experiment (28 points)\n","\n","Now comes the fun part! Your task is to define **three** new [`BatchRetrieve`](https://pyterrier.readthedocs.io/en/latest/terrier-retrieval.html#batchretrieve) objects with different word ranking methods. You are welcome to set the hyperparameters but all models should be sufficiently different. You are definitely welcome (encouraged, even!) to compare _more_ than three models too.\n","\n","Once you have defined your three `BatchRetrieve` objects, conduct an `Experiment` using all of them _at once_ (not three separate `Experiment` runs!) to evaluate the results.  Your experiment should include the two metrics used above, as well as NDCG for the top-5 and top-10 results. You are welcome to include other metrics as well\n","\n","Print the results of the Experiment and then write 2-3 sentences (or more) about what you see in the performance. Is there a clear better model? Would you expect better performance with some hyperparameter tuning?"]},{"cell_type":"code","metadata":{"id":"mRjyEZ5_aTvM","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1637299938356,"user_tz":300,"elapsed":7939,"user":{"displayName":"Junqi Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16699829542627539549"}},"outputId":"e59b1897-7f64-462b-ec2f-d46d1b5cc891"},"source":["# TODO\n","from pyterrier.measures import nDCG\n","bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n","pl2 = pt.BatchRetrieve(index, wmodel=\"PL2\")\n","lgd = pt.BatchRetrieve(index, wmodel=\"LGD\")\n","\n","pt.Experiment(\n","    [bm25, pl2, lgd], \n","    cord19.get_topics(variant='title'),\n","    cord19.get_qrels(),\n","    eval_metrics=[\"map\", \"ndcg\", nDCG@5, nDCG@10]\n",")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>map</th>\n","      <th>ndcg</th>\n","      <th>nDCG@5</th>\n","      <th>nDCG@10</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BR(BM25)</td>\n","      <td>0.181478</td>\n","      <td>0.373328</td>\n","      <td>0.611724</td>\n","      <td>0.583665</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BR(PL2)</td>\n","      <td>0.169525</td>\n","      <td>0.358597</td>\n","      <td>0.583850</td>\n","      <td>0.554204</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BR(LGD)</td>\n","      <td>0.164933</td>\n","      <td>0.359470</td>\n","      <td>0.566192</td>\n","      <td>0.563055</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       name       map      ndcg    nDCG@5   nDCG@10\n","0  BR(BM25)  0.181478  0.373328  0.611724  0.583665\n","1   BR(PL2)  0.169525  0.358597  0.583850  0.554204\n","2   BR(LGD)  0.164933  0.359470  0.566192  0.563055"]},"metadata":{},"execution_count":121}]},{"cell_type":"markdown","metadata":{"id":"wRLDodaxplsv"},"source":["From the output table above, we can clearly figure out the best model among those three is `BM25`, which has the highest score for all evaluation metrics. The `PL2` and `LGD` have a similar performance.\n","\n","I think it's possible to achieve a better performance with some hyperparameter tuning since I only use the default hyperparameter for three models here. "]},{"cell_type":"code","metadata":{"id":"Ma7_LzhuChQu"},"source":[""],"execution_count":null,"outputs":[]}]}